\chapter{Molecular dynamics}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Molecular dynamics is a method for simulating systems of particles. It is assumed that the particles behave classically -- each particle obeys Newtons second law $\sum \mb{F} = m\ddot{\rvec}$. The forces are calculated using interaction potentials, and each particle can in priciple interact with all other particles in the system:
\begin{equation}
	\mb{F}_i = -\nabla U_i(\rvec^N)
\end{equation}
Where $\rvec^N = \rvec_1, \dots, \rvec_N$ are the positions of all the particles in the system. In the simple case of two-particle interactions of one type we get:
\begin{equation}
	\mb{F}_i = \sum_{j=1}^N -\frac{\partial U(\rvec_{ij})}{\partial \rvec_{ij}}
\end{equation}

This is in principle all that is needed to do molecular dynamics (if we have a potential $U$). However, many details arise when implementing specific potentials, and when we want to control simulations. In order to get results that are relevant to the real world, we often have to apply complicated potentials. It is also common that we want to control thermodynamic properties such as temperature and pressure. While complicated potential are just rules that we impose within the framework presented above, details concerning controlling thermodynamic properties will actually alter the fundamental equations. 

There are also details concerning computational efficiency. To be able to simulate large systems over long periods of time -- large and long is relative to molecular scales -- we need methods that ignore the negligible parts of the potentials, but at the same time capture the important parts to sufficient accuracy. Usually this is done by setting a cutoff radius beyond which interactions are ignored. 

\section{Potentials}

In molecular dynamics, it is natural to define two types of interactions -- and therefore two types of potentials -- based on how they relate groups of atoms. Non-bonding interactions depend on the spatial configurations of each possible set of a specific kind, for example all triplets of Si-atoms. Bonding interactions depend on the spatial configuration of specific predfined sets of particles. The total potential is the sum of the contributions from these potentials: 

\begin{equation}
	U_{\text{tot}} = U_{\text{non-bonding}} + U_{\text{bonding}} 
\end{equation}

These definitions should not be confused with the distiction between covalent and non-covalent bonds i chemistry, even though it is common that bonding interactions in molecular dynamics represent covalent bonds.

\subsection{Non-bonding potentials}
I will use two non-bonding potentials in this thesis: Lennard-Jones and Coulomb.
A simple and widely used potential is the Lennard-Jones potential. For two particles separated by a distance $r$, the Lennard-Jones potential is:
\begin{equation}
	U_{LJ} = 4\varepsilon\left[\left(\frac{\sigma}{r}\right)^{12} - \left(\frac{\sigma}{r}\right)^{6}\right]
\end{equation}
The first term represents Pauli repulsion, and the second represents van der Waals attraction. $\sigma$ is a characteristic length which is of the same order of magnitude as the distance at which the inter-particle force is zero. $\varepsilon$ is the depth of the potentiall well -- a measure of the strength of the interaction. The Lennard-Jones potential is computationally attractive as there is no need to calculate the square roots of the distances between the particles.

The Coulomb potential -- a potential for static charges -- is used for charges particles, and is equivalent to Coulombs law:
\begin{equation}
	U_e = k\frac{q_iq_j}{r_{ij}}
\end{equation}

As an example of a simple three-particle non-bonding potential, I include the Stillinger-Weber potential @citeStillingerWeber1985:
\begin{equation}
	U_{SW} = \sum_i \sum_{j>i} \phi_2(r_{ij}) + \sum_i \sum_{j\neq i} \sum_{k>j} \phi_3(r_{ij}, r_{ik}, \theta_{ijk})
\end{equation}
\begin{equation}
	\phi_2(r_{ij}) = A\varepsilon\left[ B \left( \frac{\sigma}{r_{ij}}\right)^p-\left(\frac{\sigma}{r_{ij}}\right)^q\right]\exp\left(\frac{\sigma}{r_{ij}-a\sigma}\right)
\end{equation}
\begin{equation}
	\phi_3(r_{ij}, r_{ik}, \theta_{ijk}) = \lambda\varepsilon\left[ \cos{\theta_{ijk}} - \cos{\theta_0}\right]^2 \exp\left( \frac{\gamma\sigma}{r_{ij}-a\sigma}\right) \exp\left(\frac{\gamma \sigma}{r_{ik}-a\sigma} \right)
\end{equation}

Note the exponential tails on the potential, resulting in the potential and its derivative going to zero when $r_{ij}$ gets large.

\subsection{Bonding potentials}
Bonded potentials only apply for a specific group of particles. I give the expression for the potential energy of single groups below.
A simple two-particle bonding potential is the harmonic bond potential:
\begin{equation}
	U_{HB} = k(r_{12} - r_0)^2
\end{equation}

A simple three-particle bonding potential, which is often used in combination with the harmonic bond potential is the harmonic angle potential:
\begin{equation}
	U_{HA} = k(\theta_{123} - \theta_0)^2
\end{equation}

The latter potentials are common for creating small molecules that will not take part in chemical reactions, such as water in ice simulations. I my simulations, I will use rigid water, which effectively means that $k\to\infty$ for the harmonic bond and angle potentials. In practice the rigidity will be treated with dedicated algorithms.

\section{Time integration}
In order to solve the newtonian equations of motion numerically, a numerical scheme is needed. For particles in conservative fields -- fields in classical molecular dynamics are conservative -- the velocity Verlet scheme is usually preferred @CiteFrenkelSmit.p.69. 

\subsection{Velocity Verlet}
The velocity Verlet algorithm is:
\begin{align}
	r(t+\Delta t) &=& r(t) + v(t)\Delta t + \frac{1}{2}\frac{F(t)}{m}\Delta t^2 \\
	v(t + \Delta t) &=& v(t) + \frac{1}{2} \frac{F(t) + F(t+\Delta t)}{m}\Delta t
\end{align}
The velocity Verlet integrator is symplectic. Being symplectic can be defined in a very strict mathematical way, but for the purposes of this work, it is sufficient to note that a symplectic integrator conserves a Hamiltonian that is only slightly perturbed relative to the Hamiltonian from which it tries to solve Hamiltons equations. This in turn means that in practice it conserves energy. Therefore the velocity Verlet algorithm can be used to sample the microcanonical ensemble (NVE).

\section{Temperature}
\citet{Hunenberger2005} Says a lot about temperature and thermostats@
The instantanous temperature $T$ in molecular dynamics is defined using the equipartition theorem:
\begin{equation}
	\langle E_k \rangle = \frac{f}{2}k_B T
\end{equation}

Where $f$ is the number of kinetic degrees of freedom and $T$ is the thermodynamic temperature defined by the differential coefficient of internal energy with respect to entropy. In 3-dimensional molecular dynamics with point mass particles, and using the instant value of the kinetic energy, the instantaneous temperature can be defined as:

\begin{equation}
	\mathcal{T} \equiv \frac{2E_k}{3 Nk_B} = \frac{1}{3 k_B} \frac{1}{N}\sum_{i=1}^{N} m_iv_i^2
\end{equation}

When a temperature measure is defined, various schemes can be applied to control the temperature of a molecular dynamics simulation. Such schemes are called thermostats, and they all try to couple the MD system to an external heat bath. Some thermostats can be shown to make the system sample a known thermodynamic ensemble, whereas others do not correspond to any statistical ensemble. Thermostatting is closely related to integration in the sense that thermostatting represents a change in the integration scheme. Some thermostats, like the Nose-Hoover thermostat, explicitly change the equations of motion, while others, like the simpler Berendsen thermostat only implicitly change the equations of motion by introducing an artificial velocity rescaling. 

The simplest way to control the temperature is to rescale all velocities such that the above equation yields the correct value for the temperature -- but that results in unrealistic dynamics, and it does not represent any ensemble.

\subsection{Berendsen thermostat}
A considerable improvement from the rescaling approach is the thermostat of \citet{Berendsen1984}. The Berendsen thermostat introduces a timescale for the velocity rescaling by adding a temperature-dependant friction term to the equations of motion. The idea is to weakly couple the system to a heat bath by rescaling particle velocities to satisfy:

\begin{equation}
\frac{\dd \mathcal{T}}{dt} = \frac{T_{\text{bath}}-\mathcal{T}}{\tau}
\label{eq:berendsen}
\end{equation}

Where $T_{bath}$ is the temperature of the heat bath that is coupled to the MD-system to keep the temperature constant. This step is applied just after velocity calculation in the time integration scheme. Since the portion of energy belonging to respectively potential and kinetic energy vary in time as particles move according to the equaitions of motion, the actual value of $\mathcal{T}$ will not develop according to \ref{eq:berendsen}. The thermostat is just a mechanism that tries to push the system towards a kinetic energy corresponding to a given temperature $T_{bath}$.

\subsection{Nosé-Hoover thermostat}
The Nosé-Hoover thermostat represents a more complicated couplig to a heat bath than the Berendsen thermostat. A MD system propagated using the Nosé-Hoover thermostat will sample the canonical ensemble. 

Les us begin by writing down the Lagrangian of the MD system with no temperature control (NVE).

\begin{equation}
	\mathcal{L}(\rvec, \dot\rvec) = \frac{1}{2} \sum_{i=1}^N m_i \dot\rvec_i^2 - \mathcal{U(\rvec)}
\end{equation}

The basic idea of the Nosé-Hoover thermostat is to introduce an extra dynamic variable to the equations of motiong, effectively creating an \emph{extended} system, which is almost equal to the original system, which we will denote the \emph{real} system. The Lagrangian of the extended system is chosen to be:


\begin{equation}
	\mathcal{L}_e(\tilde\rvec, \dot{\tilde\rvec}, \tilde{s}, \dot{\tilde s}) = \frac{1}{2}\sum_{i=1}^N m_i \tilde s^2 \dot{\tilde\rvec}_i^2 - \mathcal{U}(\tilde\rvec) 
	\tikz[baseline] {
		\node [fill=green!20, anchor=base] (t1) {$+ \frac{1}{2} Q \dot{\tilde s}^2 - gk_BT_0 \ln\tilde s $};
	}
\end{equation}


First, note that the equation is now written in terms of new coordinates, which are the coordinates of the extended system. They are given below (extended system coordinates are marked with \textasciitilde): 

\begin{equation}
	\tilde\rvec = \rvec, \ \ \dot{\tilde\rvec} = \tilde s \dot\rvec, \ \ \tilde s = s, \ \ \dot{\tilde s} = \tilde s^{-1} \dot{s}
\end{equation}

The corresponding equations of motion are (in the extended system):

\begin{align}
	\ddot{\tilde\rvec}_i & = m_i^{-1} \tilde s^{-2} \tilde{\mathbf{F}}_i - 2\tilde s^{-1} \dot{\tilde s} \dot{\tilde\rvec}_i \\
	\ddot{\tilde s} & =  Q^{-1} \tilde s^{-1} \left(\sum_{i=1}m_i\tilde s^2 \dot{\tilde\rvec}_i - gk_bT_0\right)
\end{align}

This is the thermostat of \citet{Nose1984}, and in the real system it samples the canonical ensemble. However, the velocity-scaling between the real and the extended system effectively leads to uneven time intervals in the real system. Hoover later overcame this problem, and showed that the equation of motion Nosé-algorithm could be equivalently formulated in the real system as:

\begin{align}
	\ddot \rvec_i & = m_i^{-1} \mathbf{F}_i -\gamma \dot\rvec_i \\
	\dot \gamma & = -k_b f Q^{-1} \mathcal{T} \left(\frac{g}{f} \frac{T_0}{\mathcal{T}}-1\right)
\end{align}

This is known as the Nosé-Hoover thermostat \cite{PhysRevA.31.1695}. It is common to introduce a characteristic timescale for the Nosé-Hoover thermostat, since time is more intuitive than mass in MD simulations. 

\begin{equation}
	\tau_{NH} = (fk_b T_0)^{-\frac{1}{2}} Q^{\frac{1}{2}}
\end{equation}

Three types of temperature have now been introduced: Thermodynamic temperature $T$, instant temperature $\mathcal{T}$, and heat bath temperature $T_{bath}$. From here on, I will use the symbol $T$ for all of them, unless two different temperatures appear in the same equation. It should always be clear from the context what $T$ means. For example: A temperature referred from an experiment will always be a temperature measurement, which tries to measure $T$, while a temperature specified for a thermostatted molecular dynamics simulation will be $T_{bath}$.

\section{Pressure and stress tensor}
The pressure in a general classical N-body system can be expressed based on the virial equation for the pressure.

A precise formulation of the stress tensor is given in \cite{Thompson2009}.
The virial of a system consiting of N interacting particles is defined as:
\begin{equation}
	W(\rvec^N) \equiv -3V\frac{\dd U(\rvec^N)}{\dd V}
\end{equation}
Where $U$ is the potential energy of the system, which in molecular dynamics is only a function of the postitions of the particles and their interaction potentials.


\section{Cutoffs and Long range corrections}
Large-scale molecular dynamics simulations ($N \sim 10^6$) are unattainable if interactions between all particles are to be calculated. Molecular dynamics simulations with only pairwise interactions require $\mathcal{O}(N^2)$ calculations to be performed. To reduce the computational complexity, a cutoff radius $r_{cut}$ is introduced: Only interactions between particles that are closer to each other than the cutoff radius can interact. Introducing a cutoff radius reduces the time complexity of an MD simulation from $\mathcal{O}(N^2)$ to $\mathcal{O}(N)$. 

Most potentials fall off quickly, so that the error introduced by $r_{cut}$ is negligible. For some potentials however, for instance the electrostatic potential, a cutoff introduces large errors, rendering simulation results useless. Luckily, there are techniques that handle long-range interactions without explicitly calculating the forces between every pair of particles. These methods are based on a method developed by \citet{ANDP:ANDP19213690304} to calculate the energy of ionic crystals. I will briefly describe the idea of these methods, as a thorough understanding and description is out of the scope of my project.

\subsection{Ewald summation}
For Coulomb point charges with periodic boundary conditions, the electrostatic energy is:
\begin{equation}
	E_{\text{Coulomb}} = \frac{1}{2} \sum_{i=1}^N\sum_{j=1}^N \sum_{\mb{n} \in \mathbb{Z}^3} \frac{q_iq_j}{|\rvec_{ij}+\mb{n} L|} 
\end{equation}

Where the inner sum over $\mb{n}$ is over all periodic images of the system. The inner sum omits $\mb{n} = (0, 0, 0)$ when $i=j$. The idea of the Ewald summation is to divide this sum into a short-range part $E_{sr}$ and a long-rang part $E_{lr}$. The short-range contribution will be calculated in real space, and the long-range part will be calculated in Fourier space. The Fourier space calculation will deal with the Fourier transformed of the charge density:
\begin{equation}
	\tilde{\rho}(\mb{k}) = \sum_{j=1}^N q_j e^{-i\mb{k}\cdot \rvec_j}
\end{equation}
For the method to be effective, the variations in charge density in the part calculated in Fourier space must be sufficiently slowly varying so that its Fourier transform can be well represented by only a few $\mb{k}$-vectors.

There are several methods that calculate the Ewald sum. They differ for example in how they mesh the charge distribution for fourier transforms. It is crucial for computational eficiency to be able to use the fast fourier transform (FFT), so the mesh has to support FFT. In a paper concerining different methods to cacluate Ewald sums, \citet{Deserno1998} states, in a thorough paper reviewing the accuracy of mesh routines for Ewald sums, that the partilce-particle-particle-mesh routine (P$^3$M) by \citet{Hockney:1988:CSU:62815} is the ``most accurate and versatile routine'' for Ewald sums. 

\section{Measurements}

\subsection{Thermal Diffusivity}
Thermal diffusivity can be measured with the Einstein relation:
\begin{equation}
	D_E = \lim_{t\to\infty} \frac{1}{6} \frac{\dd \langle \left|\rvec(t) - \rvec(0)\right|^2\rangle}{\dd t}
	\label{eq:Einstein_diffusivity}
\end{equation}
Where `E' means that $D$ was estimated using the Einstein relation. It was shown in \cite{Yeh2004} that the diffusion coefficients in periodic simulation boxes depend on the system size, and goes like $L^{-1}$. Thus, a reference diffusivity $D_0$, corresponding to an infinite system and which can be compared with experimental results, can be found by extrapolation.

\subsection{Viscosity}
For calculating the viscosity, I use the Green-Kubo relation:
\begin{equation}
	\eta_{GK} = \frac{V}{k_B T} \int_0^\infty \langle \sigma_{\alpha\beta}(t) \sigma_{\alpha\beta}(0) \rangle\ \dd t
	\label{eq:GK_shear_viscosity}
\end{equation}
% http://www.nyu.edu/classes/tuckerman/stat.mech/lectures/lecture_21/node6.html
Where $\sigma_{\alpha\beta}$ are independent off-diagonal elements of the stress tensor of the system. These can be $\sigma_{xy}$, $\sigma_{xz}$, $\sigma_{yz}$, $(\sigma_{xx}-\sigma_{yy})/2$ and $(\sigma_{yy}-\sigma_{zz})/2$. The expectation value inside the integral assumes that a large number of systems are investigated. Through the ergodic hypothesis, we can transform the autocorrelation function to a time integral. Also, since infinite time series are not available in practice, I introduce finite bounds on the integrals. 
\begin{equation}
	\eta_{GK}(t, \tau) = \frac{V}{k_B T} \int_0^t  \frac{1}{\tau} \int_0^\tau \sigma_{\alpha\beta}(\tau'+t') \sigma_{\alpha\beta}(\tau')\ \dd \tau'\ \dd t' 
\label{eq:GK_shear_viscosity_estimate}
\end{equation}
For the purpose of estimating viscosities, the autocorrelation function is only well sampled for $t <<< \tau$. Luckily, the autocorrelation function is essentially zero for times larger that some system-specific characteristic time, which is usually in the order of picoseconds, at least for water. That means $\eta_{GK}(t, \tau)$ can provide good estimates of the viscosity for molecular dynamics simulations that last for nanoseconds.


Following \cite{Yeh2004}, it would also be possible to calculate the viscosity using the finite size effect on the thermal diffusivity.


\section{Rigid groups of particles}
There are several ways to keep a group of atoms constrained as a rigid molecule. The goal of constraint algorithms is to obtain the same positions and velocities as if the equations of motion were integrated in coordinates incorporationg the holonomic constraints, but without explicitly using these coordinates. The SHAKE algorithm by \citet{Ryckaert1977} is the most common constaint algorithm. For the particular case of three rigid atoms, like a water molecule, the SETTLE algorithm \cite{Miyamoto1992} is an analytical solution when integrating numerically the equations of motion. 
\label{sec:shake}
@MentionRelationToMinimization

\begin{comment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{SETTLE}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The basic idea of the SETTLE algorithm is to use the positions on a triangle before, $\Delta A_0 B_0 C_0$, and after, $\Delta A_1 B_1 C_1$, an unconstrained integration step to determine rotation operations to perform on $\Delta A_0 B_0 C_0$ to achieve a triangle $\Delta A_3 B_3 C_3$ corresponding to a constrained integration step. When we know the rotation operations, we also know the positions $(A_3, B_3, C_3)$ which are what we want for an implementation of the algorithm.

Let us look at the water molecule as a triangle placed in the $X'Y'$ plane of an orthogonal coordinate system $X'Y'Z'$	with the center of mass in the origin, and the oxygen atom placed on the positive y-axis. We denote the triangle $\Delta abc$ beginning with $a$ being the position of oxygen, and $b$ and $c$ the hydrogen positions in the positive direction of rotation around the origin.  In this coordinate system, the triangle is uniquely defined by three numbers: $(r_a, r_b, r_c)$ being the position components $a_y$, $-b_y$ and $c_x$. Triangles denoted by lowercase letters are the canonical water molecule, or the equilibrium configuration. $\Delta ABC$ is a triangle with possibly any positions of the corners, on which we want to perform the contrain operation to get back to the canonical triangle. 

The main derivation of the settle algorithm involve four planes, $\pi_0, \pi_A, \pi_B, \pi_C$ and the assumption that displacement vector for each apex from the unconstrained to the constrained triangle should be parallell to the plane $\pi_0$ of the triangle before the integration step. 

The actual steps to perform in the SETTLE algorithm are (in primed coordinates):
\paragraph{Positions}
\begin{enumerate}
\item Calculate $\phi$ and $\psi$: \\
$\phi$ and $\psi$ can be calculated without any knowledge of forces.
\begin{equation}
\sin\phi = \frac{Z_{A_1}'}{r_a}
\end{equation}
\begin{equation}
\sin\psi = \frac{Z_{B_1}' - Z_{C_1}'}{2r_c\cos\phi}
\end{equation}

\item Obtain intermidiate coordinates
\begin{align}
(X_{a_2}', Y_{a_2}',Z_{a_2}') &= (0, r_c\cos\phi, r_c\sin\phi)\\
(X_{b_2}', Y_{b_2}',Z_{b_2}') &= (-r_c\cos\psi, -r_b\cos\phi - r_c\sin\psi\sin\phi, -r_b\sin\phi + r_c\sin\psi\cos\phi)\\
(X_{c_2}', Y_{c_2}',Z_{c_2}') &= (r_c\cos\psi, -r_b\cos\phi + r_c\sin\psi\sin\phi, -r_b\sin\phi - r_c\sin\psi\cos\phi)
\end{align}

\item Calculate $\theta$ from assumption on forces, positions and velocities: \\
\begin{align}
	\alpha &= X'_{b_2} ( X'_{B_0}  -X'_{C_0})  +
	Y'_{b_2}( Y'_{B_0}  -Y'_{A_0}) 	+
		Y'_{c_2}( Y'_{C_0}  -Y'_{A_0}) \\
	\beta &= X'_{b_2} ( Y'_{C_0}  -Y'_{B_0})
		 		+Y'_{b_2}( X'_{B_0}  -X'_{A_0}) 	+
		 		Y'_{c_2}( X'_{C_0}  -X'_{A_0}) \\
	\gamma &= Y'_{B_1} ( X'_{B_0}  -X'_{A_0})
			-X'_{B_1}( Y'_{B_0}  -Y'_{A_0}) 	+
			Y'_{C_1}( X'_{C_0}  -X'_{A_0}) 	-
			X'_{C_1}( Y'_{C_0} - Y'_{A_0})
\end{align}
\begin{equation}
\sin \theta = \frac{\alpha\gamma - \beta \sqrt{\alpha^2 + \beta^2 - \gamma^2 )}}{\alpha^2 + \beta^2}
\end{equation}

\item Obtain final coordinates
\begin{align}
(X_{a_3}', Y_{a_3}',Z_{a_3}') &= 	(X_{a_2}' \cos\theta - Y_{a_2}'\sin\theta,
									 X_{a_2}' \sin\theta + Y_{a_2}'\cos\theta, Z_{a_2}')\\
(X_{b_3}', Y_{b_3}',Z_{b_3}') &= 	(X_{b_2}' \cos\theta - Y_{b_2}'\sin\theta, 
									 X_{b_2}' \sin\theta + Y_{b_2}'\cos\theta, Z_{b_2}')\\
(X_{c_3}', Y_{c_3}',Z_{c_3}') &=	(X_{c_2}' \cos\theta - Y_{c_2}'\sin\theta, 
									 X_{c_2}' \sin\theta + Y_{c_2}'\cos\theta, Z_{c_2}')
\end{align}
\end{enumerate}

\paragraph{Velocities}
The following is only valid within the velocity verlet algorithm.
\end{comment}