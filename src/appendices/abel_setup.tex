\chapter{Details of using the Abel computing cluster}

\section{Compiling lammps on the Abel computing cluster}
It is usually quite straightforward to install the main features of LAMMPS. However, if one is to use special features such as GPU packages or th Intel Xeon Phi, it is more complicated.

To compile LAMMPS on the Abel computer cluster, one has to load the intel compiler and mpi modules, and then follow the build instructions from the LAMMPS documentation. The program used for simulations going into this thesis, was compiled with the following command:
\begin{lstlisting}[language=Bash]
# Script to build lammps with openMP and Intel on Abel (November 21. 2014)
module load intel
module load intelmpi.intel
make yes-user-intel
make yes-user-omp
make yes-kspace
make yes-replica
make yes-molecule
make yes-rigid
make intel_cpu
\end{lstlisting}
These commands are run from {\tt src} in the LAMMPS install folder, which was extracted from a tarball.

\section{Submitting jobs}
When expanding templates, a corresponding job script is also generated. It typically looks like:
\begin{lstlisting}[language=Bash]
#!/bin/bash
# Job name:
#SBATCH --job-name=s1_hydrate_crack.in2015-02-12T11:17:08.271798
# Project: 
#SBATCH --account=myAccound
# Wall clock limit:
#SBATCH --time='10:00:00'
#SBATCH --mem-per-cpu=4000M
# CPUs:
#SBATCH --nodes=18 --ntasks-per-node=15 --cpus-per-task=1
module purge
module load intel
module load intelmpi.intel
mpirun -np 270 lmp_intel_cpu -in s1_hydrate_crack.in
\end{lstlisting}

This job script starts LAMMPS in MPI mode with 270 mpi processes.

I have made a small python module that lets me submit a job for each subdirectory containing a file {\tt lmp\_slurm\_job.sh}:

\begin{lstlisting}[language=Python]
# File: sbatch_tree.py
import subprocess
import argparse
import os.path as op
import os

def walkfunc(arg, dirname, names):
	job_script = op.join(dirname, 'lmp_slurm_job.sh')
	if op.isfile(job_script):
		if op.isfile(op.join(dirname,'log.lammps')):
			print "Seems like simulaton is running or has been run since there are output files in the folder"
			print dirname
		else:
			os.chdir(dirname)
			subprocess.call(['sbatch', 'lmp_slurm_job.sh'])
			print "Submitted from", job_script 

if __name__=='__main__':
	parser = argparse.ArgumentParser()
	parser.add_argument('sim_root_folder', type=str)
	args = parser.parse_args()
	op.walk(args.sim_root_folder, walkfunc, None)
\end{lstlisting}

Usage:
\begin{lstlisting}[language=Bash]
python -m sbatch_tree $PWD
\end{lstlisting}

\section{Experienced problems when using the Abel computing cluster}
When performing large-scale simulations, failures on the computing cluster can consume a lot of time. I have had two main problems when performing simulations on the Abel cluster, leading to seemingly random simulations not running or finishing correctly:
\begin{itemize}
\item Random node failures. Some nodes do not have the correct software settings. Small things like how each node bind the tasks to CPU-cores can make the simulation crash.
\item Slow nodes -- killed jobs. If the simulation is sent to nodes that are slower than expected, the time limit set for the simulation can be too short, and the simulation gets killed.
\end{itemize}
These kinds of failures are part of the challenge of performing large-scale computations. After simulations have been submitted, it must be checked that it was started correctly. After a simulation has stopped, it must be checked whether it stopped because it was finished, or if it was killed or crahsed.